# Copy and paste these commands into the Railway shell
# They will initialize the database schema

python3 << 'EOF'
import psycopg2
import os

print("ðŸ—„ï¸  Initializing Vermont Signal V2 Database Schema")
print("=" * 60)

# Get DATABASE_URL from environment
database_url = os.getenv('DATABASE_URL')
if not database_url:
    print("âŒ ERROR: DATABASE_URL environment variable not set")
    exit(1)

# Connect to database
print("\n1. Connecting to database...")
try:
    conn = psycopg2.connect(database_url)
    print("   âœ… Connected successfully")
except Exception as e:
    print(f"   âŒ Connection failed: {e}")
    exit(1)

# Schema SQL
schema_sql = """
CREATE TABLE IF NOT EXISTS articles (
    id SERIAL PRIMARY KEY,
    article_hash VARCHAR(64) UNIQUE NOT NULL,
    title TEXT NOT NULL,
    url TEXT UNIQUE NOT NULL,
    content TEXT,
    summary TEXT,
    source VARCHAR(255),
    author VARCHAR(255),
    published_date TIMESTAMP,
    collected_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed_date TIMESTAMP,
    processing_status VARCHAR(50) DEFAULT 'pending',
    processing_error TEXT
);

CREATE INDEX IF NOT EXISTS idx_articles_published ON articles(published_date);
CREATE INDEX IF NOT EXISTS idx_articles_source ON articles(source);
CREATE INDEX IF NOT EXISTS idx_articles_status ON articles(processing_status);
CREATE INDEX IF NOT EXISTS idx_articles_hash ON articles(article_hash);

CREATE TABLE IF NOT EXISTS extraction_results (
    id SERIAL PRIMARY KEY,
    article_id INTEGER REFERENCES articles(id) ON DELETE CASCADE,
    consensus_summary TEXT,
    claude_summary TEXT,
    gemini_summary TEXT,
    gpt_summary TEXT,
    summary_similarity_score FLOAT,
    had_conflicts BOOLEAN,
    used_arbitration BOOLEAN,
    spacy_entity_count INTEGER,
    spacy_precision FLOAT,
    spacy_recall FLOAT,
    spacy_f1_score FLOAT,
    extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    total_processing_time_seconds FLOAT,
    CONSTRAINT extraction_results_article_unique UNIQUE (article_id)
);

CREATE INDEX IF NOT EXISTS idx_extraction_article ON extraction_results(article_id);

CREATE TABLE IF NOT EXISTS facts (
    id SERIAL PRIMARY KEY,
    article_id INTEGER REFERENCES articles(id) ON DELETE CASCADE,
    extraction_result_id INTEGER REFERENCES extraction_results(id) ON DELETE CASCADE,
    entity TEXT NOT NULL,
    entity_type VARCHAR(50),
    event_description TEXT,
    confidence FLOAT,
    source_models TEXT[],
    wikidata_id VARCHAR(50),
    wikidata_label TEXT,
    wikidata_description TEXT,
    wikidata_properties JSONB,
    note TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_facts_article ON facts(article_id);
CREATE INDEX IF NOT EXISTS idx_facts_entity_type ON facts(entity_type);
CREATE INDEX IF NOT EXISTS idx_facts_confidence ON facts(confidence);
CREATE INDEX IF NOT EXISTS idx_facts_wikidata ON facts(wikidata_id);

CREATE TABLE IF NOT EXISTS entity_relationships (
    id SERIAL PRIMARY KEY,
    article_id INTEGER REFERENCES articles(id) ON DELETE CASCADE,
    entity_a TEXT NOT NULL,
    entity_b TEXT NOT NULL,
    relationship_type VARCHAR(100),
    relationship_description TEXT,
    confidence FLOAT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT unique_relationship UNIQUE (article_id, entity_a, entity_b, relationship_type)
);

CREATE INDEX IF NOT EXISTS idx_relationships_article ON entity_relationships(article_id);
CREATE INDEX IF NOT EXISTS idx_relationships_entity_a ON entity_relationships(entity_a);
CREATE INDEX IF NOT EXISTS idx_relationships_entity_b ON entity_relationships(entity_b);

CREATE TABLE IF NOT EXISTS api_costs (
    id SERIAL PRIMARY KEY,
    article_id INTEGER REFERENCES articles(id) ON DELETE SET NULL,
    api_provider VARCHAR(50),
    model VARCHAR(100),
    operation_type VARCHAR(100),
    input_tokens INTEGER,
    output_tokens INTEGER,
    total_tokens INTEGER,
    cost FLOAT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_costs_timestamp ON api_costs(timestamp);
CREATE INDEX IF NOT EXISTS idx_costs_article ON api_costs(article_id);
CREATE INDEX IF NOT EXISTS idx_costs_provider ON api_costs(api_provider);

CREATE TABLE IF NOT EXISTS corpus_topics (
    id SERIAL PRIMARY KEY,
    topic_id INTEGER,
    topic_label TEXT,
    keywords TEXT[],
    representative_docs TEXT[],
    article_count INTEGER,
    computed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    corpus_size INTEGER,
    CONSTRAINT unique_topic UNIQUE (topic_id, computed_at)
);

CREATE INDEX IF NOT EXISTS idx_topics_computed ON corpus_topics(computed_at);

CREATE TABLE IF NOT EXISTS article_topics (
    id SERIAL PRIMARY KEY,
    article_id INTEGER REFERENCES articles(id) ON DELETE CASCADE,
    topic_id INTEGER,
    probability FLOAT,
    CONSTRAINT unique_article_topic UNIQUE (article_id, topic_id)
);

CREATE INDEX IF NOT EXISTS idx_article_topics_article ON article_topics(article_id);
CREATE INDEX IF NOT EXISTS idx_article_topics_topic ON article_topics(topic_id);
"""

# Execute schema
print("\n2. Creating tables...")
try:
    with conn.cursor() as cur:
        cur.execute(schema_sql)
        conn.commit()
    print("   âœ… Schema created successfully")
except Exception as e:
    print(f"   âŒ Failed: {e}")
    conn.rollback()
    conn.close()
    exit(1)

# Verify tables
print("\n3. Verifying tables...")
with conn.cursor() as cur:
    cur.execute("""
        SELECT table_name
        FROM information_schema.tables
        WHERE table_schema = 'public'
        ORDER BY table_name
    """)
    tables = [row[0] for row in cur.fetchall()]

    expected_tables = [
        'articles', 'extraction_results', 'facts',
        'entity_relationships', 'api_costs',
        'corpus_topics', 'article_topics'
    ]

    all_good = True
    for table in expected_tables:
        if table in tables:
            print(f"   âœ… {table}")
        else:
            print(f"   âŒ {table} - MISSING")
            all_good = False

conn.close()

print("\n" + "=" * 60)
if all_good:
    print("âœ… Database initialization complete!")
    print("\nYou can now:")
    print("  â€¢ Import articles from V1")
    print("  â€¢ Run the batch processor")
    print("  â€¢ Access the API endpoints")
else:
    print("âŒ Some tables are missing")

EOF
