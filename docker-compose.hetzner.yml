# Vermont Signal V2 - Hetzner Cloud Deployment
# Single-server architecture with persistent ML model caching
# Run with: docker compose -f docker-compose.hetzner.yml up -d

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: vermont-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: vermont_signal
      POSTGRES_USER: vermont_signal
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD:-changeme123}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./schema.sql:/docker-entrypoint-initdb.d/schema.sql:ro
    networks:
      - vermont-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U vermont_signal"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # FastAPI Backend
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: vermont-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://vermont_signal:${DATABASE_PASSWORD:-changeme123}@postgres:5432/vermont_signal
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ADMIN_API_KEY=${ADMIN_API_KEY}
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:3000}
      - PORT=8000
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - vermont-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Worker (ML Models + Batch Processing)
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: vermont-worker
    restart: unless-stopped
    environment:
      # Use individual params to avoid URL encoding issues with special chars in password
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_NAME=vermont_signal
      - DATABASE_USER=vermont_signal
      - DATABASE_PASSWORD=${DATABASE_PASSWORD:-changeme123}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # ML Model cache directories
      - TRANSFORMERS_CACHE=/models/transformers
      - HF_HOME=/models/huggingface
      - SPACY_DATA=/models/spacy
    volumes:
      # Persistent ML model cache - key feature for fast deploys!
      - ml_models:/models
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - vermont-network
    deploy:
      resources:
        limits:
          memory: 5G
        reservations:
          memory: 3G

  # Next.js Frontend
  frontend:
    build:
      context: ./web
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_API_URL: /api
    container_name: vermont-frontend
    restart: unless-stopped
    environment:
      - NEXT_PUBLIC_API_URL=/api
      - API_URL=http://api:8000/api
    depends_on:
      - api
    networks:
      - vermont-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Caddy Reverse Proxy (Auto HTTPS)
  caddy:
    image: caddy:2-alpine
    container_name: vermont-caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"  # HTTP/3
    environment:
      - DOMAIN=${DOMAIN:-}
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - api
      - frontend
    networks:
      - vermont-network
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

volumes:
  # PostgreSQL data
  postgres_data:
    driver: local

  # ML model cache - persists across deployments!
  # spaCy transformers: ~2GB
  # HuggingFace models: ~3GB
  # BERTopic cache: ~1GB
  ml_models:
    driver: local

  # Caddy data (TLS certificates)
  caddy_data:
    driver: local

  # Caddy config
  caddy_config:
    driver: local

networks:
  vermont-network:
    driver: bridge
