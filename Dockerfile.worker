# ============================================================================
# Stage 1: Builder - Install dependencies with build tools
# ============================================================================
FROM python:3.11-slim AS builder

WORKDIR /build

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies to user directory
RUN pip install --user --no-cache-dir -r requirements.txt

# Install additional worker dependencies
RUN pip install --user --no-cache-dir psycopg2-binary==2.9.10 b2sdk==2.6.0

# Download full transformer model for Railway (no size limits!)
# F1 score ~0.96, best accuracy
RUN python -m spacy download en_core_web_trf


# ============================================================================
# Stage 2: Runtime - Minimal production image with ML tools
# ============================================================================
FROM python:3.11-slim

ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

WORKDIR /app

# Install only runtime dependencies (no build tools!)
RUN apt-get update && apt-get install -y \
    postgresql-client \
    cron \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy Python packages from builder
COPY --from=builder /root/.local /root/.local

# Make sure scripts in .local are usable
ENV PATH=/root/.local/bin:$PATH

# Download spaCy model in runtime stage (since builder stage copy doesn't work)
RUN python -m spacy download en_core_web_trf

# Copy application files
COPY vermont_news_analyzer/ vermont_news_analyzer/
COPY scripts/ scripts/

# Create necessary directories
RUN mkdir -p vermont_news_analyzer/data/cache vermont_news_analyzer/logs logs

# Create cron jobs for RSS collection and batch processing
RUN echo '# Vermont Signal V2 Scheduled Jobs' > /etc/cron.d/v2-jobs && \
    echo 'SHELL=/bin/bash' >> /etc/cron.d/v2-jobs && \
    echo 'PATH=/usr/local/bin:/usr/bin:/bin' >> /etc/cron.d/v2-jobs && \
    echo '' >> /etc/cron.d/v2-jobs && \
    echo '# Collect RSS feeds every 4 hours' >> /etc/cron.d/v2-jobs && \
    echo '0 */4 * * * root cd /app && env $(cat /app/.env | xargs) /usr/local/bin/python scripts/collect_news.py >> /app/logs/collector.log 2>&1' >> /etc/cron.d/v2-jobs && \
    echo '' >> /etc/cron.d/v2-jobs && \
    echo '# Process collected articles at 2am ET (7am UTC)' >> /etc/cron.d/v2-jobs && \
    echo '0 7 * * * root cd /app && env $(cat /app/.env | xargs) /usr/local/bin/python -m vermont_news_analyzer.batch_processor --limit 50 >> /app/logs/batch.log 2>&1' >> /etc/cron.d/v2-jobs && \
    echo '' >> /etc/cron.d/v2-jobs && \
    echo '# Compute topics weekly on Sundays at 3am ET (8am UTC)' >> /etc/cron.d/v2-jobs && \
    echo '0 8 * * 0 root cd /app && env $(cat /app/.env | xargs) /usr/local/bin/python scripts/compute_topics.py --days 90 --min-topic-size 3 >> /app/logs/topics.log 2>&1' >> /etc/cron.d/v2-jobs && \
    echo '' >> /etc/cron.d/v2-jobs && \
    echo '# Backup database daily at 4am ET (9am UTC)' >> /etc/cron.d/v2-jobs && \
    echo '0 9 * * * root /bin/bash /app/scripts/backup_database.sh >> /app/logs/backup.log 2>&1' >> /etc/cron.d/v2-jobs && \
    echo '' >> /etc/cron.d/v2-jobs && \
    echo '# Upload backup to Backblaze B2 at 4:15am ET (9:15am UTC)' >> /etc/cron.d/v2-jobs && \
    echo '15 9 * * * root cd /app && env $(cat /app/.env | xargs) /bin/bash /app/scripts/backup_to_cloud.sh >> /app/logs/cloud_backup.log 2>&1' >> /etc/cron.d/v2-jobs && \
    echo '' >> /etc/cron.d/v2-jobs

RUN chmod 0644 /etc/cron.d/v2-jobs
RUN crontab /etc/cron.d/v2-jobs
RUN touch /var/log/cron.log /app/logs/batch.log /app/logs/collector.log /app/logs/topics.log /app/logs/backup.log /app/logs/cloud_backup.log

# Create startup script
RUN echo '#!/bin/bash\n\
set -e\n\
echo "Vermont Signal V2 Worker starting..."\n\
\n\
# Validate dependencies before starting\n\
echo ""\n\
echo "Validating dependencies..."\n\
if ! python scripts/validate_dependencies.py; then\n\
    echo "ERROR: Dependency validation failed. Cannot start worker."\n\
    exit 1\n\
fi\n\
echo ""\n\
\n\
# Export environment variables to file for cron jobs\n\
echo "Exporting environment variables for cron..."\n\
printenv | grep -E "^(DATABASE_|ANTHROPIC_|GOOGLE_|OPENAI_|CLAUDE_|GEMINI_|B2_)" > /app/.env\n\
\n\
echo "Initializing database schema..."\n\
python -c "from vermont_news_analyzer.modules.database import VermontSignalDatabase; db = VermontSignalDatabase(); db.connect(); db.init_schema(); db.disconnect()" 2>&1 | tee /app/logs/init.log\n\
\n\
echo "Running initial RSS collection..."\n\
python scripts/collect_news.py 2>&1 | tee /app/logs/startup-collector.log\n\
\n\
echo "Running initial batch processing (50 articles)..."\n\
python -m vermont_news_analyzer.batch_processor --limit 50 2>&1 | tee /app/logs/startup-batch.log\n\
\n\
echo "Worker initialized."\n\
echo "  - RSS Collection: Every 4 hours"\n\
echo "  - Batch Processing: Daily at 2am ET (7am UTC)"\n\
echo "  - Topic Computation: Sundays at 3am ET (8am UTC)"\n\
echo "  - Database Backup: Daily at 4am ET (9am UTC)"\n\
echo "  - Cloud Backup (B2): Daily at 4:15am ET (9:15am UTC)"\n\
echo "Starting cron for scheduled runs..."\n\
cron\n\
tail -f /var/log/cron.log /app/logs/*.log\n\
' > /app/start.sh && chmod +x /app/start.sh

CMD ["/app/start.sh"]
